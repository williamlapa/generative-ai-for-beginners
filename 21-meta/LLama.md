Aqui estÃ¡ a traduÃ§Ã£o do arquivo  **README_LLAMA.md** , jÃ¡ incorporando as atualizaÃ§Ãµes mais recentes do Llama 3.2 e 3.3.

---

# Construindo com a FamÃ­lia de Modelos Meta

## IntroduÃ§Ã£o

Esta liÃ§Ã£o abordarÃ¡:

* ExploraÃ§Ã£o dos dois principais modelos da famÃ­lia Meta - **Llama 3.1** e  **Llama 3.2** .
* CompreensÃ£o dos casos de uso e cenÃ¡rios para cada modelo.
* Exemplos de cÃ³digo para demonstrar os recursos exclusivos de cada modelo.

---

## **A FamÃ­lia de Modelos Meta**

Nesta liÃ§Ã£o, exploraremos **dois modelos** da famÃ­lia Meta, tambÃ©m chamada de  **"Rebanho Llama"** : **Llama 3.1** e  **Llama 3.2** .

Esses modelos estÃ£o disponÃ­veis em diferentes variantes no marketplace do GitHub Model. Veja mais detalhes sobre como usar GitHub Models para [prototipagem com IA](https://docs.github.com/en/github-models/prototyping-with-ai-models?WT.mc_id=academic-105485-koreyst).

### **Variantes dos Modelos:**

* **Llama 3.1 - 70B Instruct**
* **Llama 3.1 - 405B Instruct**
* **Llama 3.2 - 11B Vision Instruct**
* **Llama 3.2 - 90B Vision Instruct**

> *Nota: O Llama 3 tambÃ©m estÃ¡ disponÃ­vel no GitHub Models, mas nÃ£o serÃ¡ abordado nesta liÃ§Ã£o.*

---

## **Llama 3.1**

Com  **405 bilhÃµes de parÃ¢metros** , o **Llama 3.1** Ã© um **LLM de cÃ³digo aberto** altamente avanÃ§ado.

Esta versÃ£o aprimora o  **Llama 3** , trazendo:

* **Janela de contexto maior** â†’ **128k tokens** vs  **8k tokens** .
* **Maior limite de saÃ­da** â†’ **4096 tokens** vs  **2048 tokens** .
* **Melhor suporte multilÃ­ngue** â†’ GraÃ§as ao aumento no volume de dados de treinamento.

Essas melhorias tornam o **Llama 3.1** ideal para aplicaÃ§Ãµes avanÃ§adas de IA generativa, incluindo:

âœ… **Chamadas de funÃ§Ã£o nativas** â†’ Capacidade de chamar ferramentas externas e APIs diretamente.

âœ… **Melhor desempenho em RAG (GeraÃ§Ã£o Aumentada por RecuperaÃ§Ã£o)** â†’ Devido Ã  grande janela de contexto.

âœ… **GeraÃ§Ã£o de dados sintÃ©ticos** â†’ Para melhorar tarefas como  **fine-tuning** .

---

### **Chamadas de FunÃ§Ã£o Nativas (Function Calling)**

O **Llama 3.1** foi refinado para realizar chamadas de funÃ§Ãµes e ferramentas externas. Ele jÃ¡ inclui dois  **ferramentas nativas** :

ğŸ” **Brave Search** â†’ Realiza buscas na web para obter informaÃ§Ãµes atualizadas, como previsÃ£o do tempo.

ğŸ“Š **Wolfram Alpha** â†’ Resolve cÃ¡lculos matemÃ¡ticos complexos, eliminando a necessidade de criar funÃ§Ãµes personalizadas.

TambÃ©m Ã© possÃ­vel criar **ferramentas personalizadas** que o modelo pode chamar.

#### Exemplo de CÃ³digo: Chamando o Brave Search

```python
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import AssistantMessage, SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

token = os.environ["GITHUB_TOKEN"]
endpoint = "https://models.inference.ai.azure.com"
model_name = "meta-llama-3.1-405b-instruct"

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

tool_prompt=f"""
<|begin_of_text|><|start_header_id|>system<|end_header_id|>

Ambiente: ipython
Ferramentas: brave_search, wolfram_alpha
Data limite do conhecimento: Dezembro de 2023
Data de hoje: 23 de julho de 2024

VocÃª Ã© um assistente Ãºtil<|eot_id|>
"""

messages = [
    SystemMessage(content=tool_prompt),
    UserMessage(content="Qual Ã© a previsÃ£o do tempo em Estocolmo?"),
]

response = client.complete(messages=messages, model=model_name)

print(response.choices[0].message.content)
```

---

## **Llama 3.2**

Apesar de ser um  **LLM** , o **Llama 3.1** **nÃ£o suporta multimodalidade** (entrada de imagens e texto).

O **Llama 3.2** resolve essa limitaÃ§Ã£o, permitindo  **processar imagens e texto simultaneamente** .

### **Principais Recursos do Llama 3.2:**

âœ… **Multimodalidade** â†’ Capacidade de entender imagens e texto.

âœ… **Variantes de pequeno a mÃ©dio porte** â†’ Modelos de **11B** e **90B** parÃ¢metros, oferecendo flexibilidade de implantaÃ§Ã£o.

âœ… **VersÃµes somente texto (1B e 3B parÃ¢metros)** â†’ Permitem execuÃ§Ã£o eficiente em  **dispositivos mÃ³veis e edge computing** , com baixa latÃªncia.

A adiÃ§Ã£o do suporte multimodal representa um grande avanÃ§o no mundo dos  **LLMs open-source** .

#### Exemplo de CÃ³digo: Processando Imagens com Llama 3.2

```python
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import (
    SystemMessage,
    UserMessage,
    TextContentItem,
    ImageContentItem,
    ImageUrl,
    ImageDetailLevel,
)
from azure.core.credentials import AzureKeyCredential

token = os.environ["GITHUB_TOKEN"]
endpoint = "https://models.inference.ai.azure.com"
model_name = "Llama-3.2-90B-Vision-Instruct"

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

response = client.complete(
    messages=[
        SystemMessage(content="VocÃª Ã© um assistente Ãºtil que descreve imagens em detalhes."),
        UserMessage(
            content=[
                TextContentItem(text="O que hÃ¡ nesta imagem?"),
                ImageContentItem(
                    image_url=ImageUrl.load(
                        image_file="sample.jpg",
                        image_format="jpg",
                        detail=ImageDetailLevel.LOW)
                ),
            ],
        ),
    ],
    model=model_name,
)

print(response.choices[0].message.content)
```

---

## **ğŸ”¥ AtualizaÃ§Ã£o: LanÃ§amento do Llama 3.3 70B (Dezembro de 2024)**

A Meta lanÃ§ou recentemente o  **Llama 3.3 70B** , um modelo otimizado com melhorias em eficiÃªncia e custo-benefÃ­cio:

âœ… **Desempenho comparÃ¡vel ao Llama 3.1 405B** â†’ Mas com  **menor consumo de recursos** .

âœ… **Melhoria no raciocÃ­nio e compreensÃ£o matemÃ¡tica** â†’ Melhor desempenho em benchmarks de lÃ³gica.

âœ… **DisponÃ­vel no Amazon Bedrock** â†’ IntegraÃ§Ã£o simplificada para aplicaÃ§Ãµes empresariais.

ğŸ”— Mais detalhes: [AWS Amazon](https://aws.amazon.com/pt/about-aws/whats-new/2024/12/metas-llama-3-3-70b-model-amazon-bedrock/?utm_source=chatgpt.com)

---

## **Continue sua Jornada no Aprendizado!**

Agora que vocÃª aprendeu sobre os modelos  **Llama 3.1, 3.2 e 3.3** , explore mais sobre IA generativa na nossa [coleÃ§Ã£o de aprendizado](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst).

ğŸš€ **O futuro da IA generativa estÃ¡ na sua mÃ£o!** ğŸš€

---

Se precisar de mais alguma adaptaÃ§Ã£o, me avise! ğŸ˜ƒ
